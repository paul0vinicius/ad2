---
title: "Regressão Logística"
author: "Paulo Vinicius Soares"
date: "26 de fevereiro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(readr)
library(knitr)
library(tidyverse)
library(caret)
source("../utils/importa_dados_deputados.R")
```

Nessa atividade você irá usar seus conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados serão eleitos nas eleições de 2014. De forma específica faremos o seguinte:

```{r}
deputados <- get_kaggle_data()
```


1.Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador?

```{r}
# Frequência de eleitos e não eleitos
deputados %>%
  ggplot(aes(situacao_final)) + geom_histogram(stat="count")
```

Em primeira instância ocorre o perigo de enviesamento da previsão para uma das classes presentes nos dados. Como a proporção de deputados não eleitos para eleitos é de aproximadamente x para y, é muito provável que ele preveja "não eleito" para determinados casos. Isso pode ocorrer ao utilizar os algoritmos de Árvore de Decisão porque (Inserir explicação aqui sobre como o algoritmo funciona).

Soluções: Undersampling (Classes majoritárias) ou Oversampling (Classes minoritárias)
Verificar pacote unbalanced

2.Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.

```{r}
# Dividir os dados em treino e teste

dataPartition <- createDataPartition(y = deputados$situacao_final, p=0.75, list=FALSE)

treino <- deputados[dataPartition,]
teste <- deputados[-dataPartition,]
```

```{r}
# Validação cruzada
fitControlUndersampling <- trainControl(method = "repeatedcv", number = 5, repeats = 5, sampling="down")
fitControlOversampling <- trainControl(method = "repeatedcv", number = 5, repeats = 5, sampling="up")

preProcessing <- c("scale", "center", "nzv")

treino <- treino %>% 
  select(-nome, -ID, -numero_cadidato, -setor_economico_despesa, -setor_economico_receita, -partido)

teste <- teste %>% 
  mutate(is_deputado = ifelse(descricao_ocupacao=="DEPUTADO",TRUE,FALSE), 
         is_homem = ifelse(sexo=="MASCULINO",TRUE,FALSE), 
         is_superior_completo=ifelse(grau=="SUPERIOR COMPLETO",TRUE,FALSE))

formula_modelo <- as.formula(situacao_final ~ .)
```


Regressão logística
```{r}
modelo_regressao <- train(formula_modelo, data = treino, method="glm", family="binomial", 
                          na.action = na.omit, trControl = fitControlOversampling, preProcess = preProcessing)

summary(modelo_regressao)
```

Árvore de decisão
```{r}
modelo_arvore <- train(formula_modelo, data=dados_treino_remastered, method="rpart", na.action = na.omit, 
                       trControl = fitControlOversampling, preProcess = preProcessing, cp=0.001, maxdepth=20)

modelo_arvore
```

Usando Adaboost
```{r}
dados_treino_remastered <- treino %>%
  mutate(is_deputado = ifelse(descricao_ocupacao=="DEPUTADO",TRUE,FALSE), 
         is_homem = ifelse(sexo=="MASCULINO",TRUE,FALSE), 
         is_superior_completo=ifelse(grau=="SUPERIOR COMPLETO",TRUE,FALSE)) %>%
  select(-UF,-total_despesa,-idade,-estado_civil,-descricao_cor_raca,-descricao_ocupacao,-sexo,-grau)
modelo_adaboost <- train(formula_modelo, data=dados_treino_remastered, method="adaboost", na.action = na.omit, 
                         preProcess = preProcessing)

modelo_adaboost
```

```{r}
predictions <- predict(modelo_arvore, teste)

confusionMatrix(predictions, teste$situacao_final)
```


3.Reporte acurácia, precision, recall e f-measure no treino e validação. Como você avalia os resultados? Justifique sua resposta.

Eu achei bom e alto.

4.Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo

5.Envie seus melhores modelos à competição do Kaggle. Sugestões abaixo:
  5.a Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting)
  5.b Crie novos atributos.
