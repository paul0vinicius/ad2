---
title: "Regressão Logística"
author: "Paulo Vinicius Soares"
date: "26 de fevereiro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(readr)
library(knitr)
library(tidyverse)
library(caret)
source("../utils/importa_dados_deputados.R")
```

Nessa atividade você irá usar seus conhecimentos sobre classificação para prever quais candidatos à Câmara de Deputados serão eleitos nas eleições de 2014. De forma específica faremos o seguinte:

```{r}
deputados <- get_kaggle_data()
```


1.Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador?

```{r}
# Frequência de eleitos e não eleitos
deputados %>%
  ggplot(aes(situacao_final)) + geom_histogram(stat="count")
```

Em primeira instância ocorre o perigo de enviesamento da previsão para uma das classes presentes nos dados. Como a proporção de deputados não eleitos para eleitos é de aproximadamente x para y, é muito provável que ele preveja "não eleito" para determinados casos. Isso pode ocorrer ao utilizar os algoritmos de Árvore de Decisão porque (Inserir explicação aqui sobre como o algoritmo funciona).

Soluções: Undersampling (Classes majoritárias) ou Oversampling (Classes minoritárias)
Verificar pacote unbalanced

2.Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.

```{r}
# Dividir os dados em treino e teste

dataPartition <- createDataPartition(y = deputados$situacao_final, p=0.75, list=FALSE)

treino <- deputados[dataPartition,]
teste <- deputados[-dataPartition,]
```

```{r}
# Validação cruzada
fitControlUndersampling <- trainControl(method = "repeatedcv", number = 5, repeats = 5, sampling="down")
fitControlOversampling <- trainControl(method = "repeatedcv", number = 5, repeats = 5, sampling="up")

preProcessing <- c("scale", "center", "nzv")

treino <- treino %>% 
  select(-nome, -ID, -numero_cadidato, -setor_economico_despesa, -setor_economico_receita, -partido)
```


Regressão logística
```{r}
modelo_regressao <- train(situacao_final ~ ., data = treino, method="glm", family="binomial", 
                          na.action = na.omit, trControl = fitControlOversampling, preProcess = preProcessing)

summary(modelo_regressao)
```



3.Reporte acurácia, precision, recall e f-measure no treino e validação. Como você avalia os resultados? Justifique sua resposta.

4.Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo

5.Envie seus melhores modelos à competição do Kaggle. Sugestões abaixo:
  5.a Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting)
  5.b Crie novos atributos.
